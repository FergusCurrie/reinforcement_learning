{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f31d6b9-3706-4fee-9f70-60aaeefde023",
   "metadata": {},
   "source": [
    "# Sutton \n",
    "\n",
    "Algorithms:\n",
    "- bandits \n",
    "    - thompson sampling \n",
    "    - ucb \n",
    "    - epsilon greedy\n",
    "    - gradient bandit\n",
    "    - online method / incremental mean \n",
    "- mdp\n",
    "    - policy iteration\n",
    "    - value iteration \n",
    "    - LP formulation\n",
    "    - monte carlo prediction\n",
    "    - monte carlo exploring start \n",
    "    - first visti mc control epsilon soft policy\n",
    "    - off policy w importance sampling. weighted, ordinary \n",
    "    - off policy mc \n",
    "    - td prediction / td(0)\n",
    "    - sarsa (0)\n",
    "    - q-learning \n",
    "    - expected sarsa\n",
    "    - double learning \n",
    "    - nstep td prediction\n",
    "    - n-step sarsa \n",
    "    - n-step off policy\n",
    "    - n-step tree backup\n",
    "    - n-step q(sigma)\n",
    "- mpd with policy gradient \n",
    "    - policy grad\n",
    "    - restricted grad update\n",
    "    - natural grad update\n",
    "    - trust region update\n",
    "    - clmaped surrogate objective \n",
    "    \n",
    "Problems:\n",
    "- bandits can just use a number of normal distributions. \n",
    "- mdp, hex world\n",
    "- also can use markov reward process "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b603c4c-a37c-4d09-b96f-0f1f9ebbcfc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dlvenv",
   "language": "python",
   "name": "dlvenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
